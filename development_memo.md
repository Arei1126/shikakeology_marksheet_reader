## Shikakeology MarkSheet Reader 開発・仕様ガイド

このドキュメントは、MarkSheet Reader Proの背後にある理論的背景、マークシートの物理的仕様、およびデータ処理ロジックについて解説するものです。
今後の開発やメンテナンス、および新規開発者がプロジェクトに参加する際のオンボーディング資料として活用してください。

### 1. 理論的背景：仕掛学に基づく行動変容プロセス

本アプリケーションは、単なるマークシート読み取りツールではなく、**「仕掛学（Shikakeology）」**に基づく行動観察データを分析するためのツールです。
通行人が仕掛けに対してどのように反応し、行動を変容させたかを「関与の深さ」によって段階的に記録します。

#### 1.1. 行動の階層モデル (Behavioral Funnel)

観察対象者の行動は、以下の4段階のプロセス（ファネル）として定義されています。段階が進むほど、関与度が深くなります。

- ##### Step 0: 通行 (Passing)

    - 定義: 観察エリアを通過したすべての人。

    - 記録: 性別（Male/Female）をチェックすることで「通行した」とみなします。

    - 意味: 分母となる総数。

- ##### Step 1: 気づいた (Look / Noticed)

    - 定義: 仕掛けや対象物に視線を向けた、または存在を認識した行動。

    - マークシート上の表記: 見た

- ##### Step 2: 立ち止まった (Stop / Stopped)

    - 定義: 歩みを止め、対象物を詳しく観察したり、近づいたりした行動。

    - マークシート上の表記: 立ち止まった

- #### Step 3: 使った (Use / Used)

    - 定義: 仕掛けに対して能動的なアクションを起こした（例：消毒液を使った、ゴミを捨てた、ボタンを押した）行動。

    - マークシート上の表記: 使った

#### 1.2. データ補完ロジック (Hierarchical Imputation)

この行動モデルは「包含関係」にあります。
**「使った（Step 3）」人は、必然的に「立ち止まり（Step 2）」、「気づいて（Step 1）」います。**

したがって、アプリの読み取りロジックには以下の自動補完ルールが組み込まれています。

- Use がマークされている → Stop と Look も自動的に有効（TRUE）にする。

- Stop がマークされている → Look も自動的に有効（TRUE）にする。

これにより、現場の記録者は「最終到達地点（例：使った）」だけをマークすれば良く、記録負荷を軽減しつつ、データ分析時には正しいファネル分析が可能になります。

### 2. マークシートの物理仕様

読み取り対象となるマークシートは、画像処理による自動認識を前提に設計されています。

#### 2.1. 基本レイアウト

- 用紙サイズ: A4縦（推奨）

- オリエンテーション: 縦向き

- マーカー: 4隅に ArUcoマーカー (4x4, Dictionary 50) を配置。

    - 左上: ID 0

    - 右上: ID 1

    - 右下: ID 2

    - 左下: ID 3

    - ※ アプリはマーカーの「内側の角」を基準点として歪み補正（射影変換）を行います。

#### 2.2. データグリッド構造

シート全体は、横方向に 4つのブロック（4人分） に分割されています。

- 行数: 全61行

    - 行0: ヘッダー/インデックス行（読み取り対象外）

    - 行1〜60: データ記録行

- 列構成: 1ブロックあたり6列

    - No. : 通し番号（視認用、読み取り時は無視）

    - Male : 男性（チェックでStep 0有効）

    - Female : 女性（チェックでStep 0有効）

    - Look : 気づいた

    - Stop : 立ち止まった

    - Use : 使った

全体では 6列 × 4ブロック = 24列 のグリッドとして画像処理されます。

### 3. ID割り振りルール（重要）

データのID（通し番号）の割り振り方は、「各ブロック内で縦方向に進む」 方式を採用しています。
一般的な「左から右へ（Z字型）」ではないため、注意が必要です。

#### 割り振り順序

1. 左端のブロック (Block 1): 上から下へ (ID 1 〜 60)

1. 2番目のブロック (Block 2): 上から下へ (ID 61 〜 120)

1. 3番目のブロック (Block 3): 上から下へ (ID 121 〜 180)

1. 右端のブロック (Block 4): 上から下へ (ID 181 〜 240)

#### シートあたりの収容人数

- 1枚あたり 最大240人 分のデータを記録可能です。

### 4. 技術スタックと処理フロー

#### 4.1. 主要ライブラリ

- OpenCV.js: 画像処理のコア。WebAssemblyで動作し、サーバーサイド処理を必要としません。

- React + Vite: UIフレームワークとビルドツール。

- Tailwind CSS: スタイリング。

#### 4.2. 処理パイプライン

1. 画像アップロード: ブラウザ上で画像ファイルを読み込み。

1. 前処理: グレースケール化、適応的閾値処理による二値化。

1. マーカー検出: cv.findContours 等を用いて四角形を検出し、4隅のArUcoマーカー（または矩形）を特定。

1. 幾何補正: 4隅の座標を基に cv.warpPerspective で画像を正方形（長方形）に補正。

1. グリッドサンプリング: 補正後の画像を 61行 × 24列 に分割し、各セルの「黒色画素率」を計算。

1. 判定 & 構造化:

    - 閾値（デフォルト0.2）を超えたらマークありと判定。

    - 前述の「仕掛学ロジック」を適用してデータを整形。

    - ブロックごとの縦優先ルールに従ってIDを付与。

1. CSV出力: 回帰分析用（Rawデータ）と基本統計用の2種類を生成。

#### 5. デバッグとチューニング

- 閾値調整: 照明条件や筆記具の濃さに応じて、設定画面から「黒色判定しきい値」を調整可能です。

- デバッグビュー: 補正後の画像にグリッド線を重ねて表示します
